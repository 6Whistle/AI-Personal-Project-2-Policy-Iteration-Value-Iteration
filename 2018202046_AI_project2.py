# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16lLZdzNQJ5BY-QWRc9p0NzPmTqWmKcQL
"""

import numpy as np

def getState(s, a, grid_size = 7):
    A = [(-1, 0), (1, 0), (0, -1), (0, 1)]
    s[0] += A[a][0]
    s[1] += A[a][1]

    if(s[0] < 0):
        s[0] = 0
    elif(s[0] > grid_size - 1):
        s[0] = grid_size - 1

    if(s[1] < 0):
        s[1] = 0
    elif(s[1] > grid_size - 1):
        s[1] = grid_size - 1

    return s[0], s[1]

def getRewardTable(grid_size = 7):
    reward_t = np.full([grid_size, grid_size], -1)
    reward_t[0][2] = -100
    reward_t[1][2] = -100
    reward_t[grid_size - 1][2] = -100
    reward_t[grid_size - 1][3] = -100
    reward_t[3][4] = -100
    reward_t[3][5] = -100
    reward_t[grid_size - 1][grid_size - 1] = 0

    return reward_t

def policy_eval(iter, grid_size = 7):
    post_value_t = np.full([grid_size, grid_size], -1.0)      
    reward_t = getRewardTable()

    for i in range(iter):
        temp = np.full([grid_size, grid_size], 0.0)
        for j in range(grid_size):
            for k in range (grid_size):
                if j == k and j == grid_size - 1:
                    temp[j][k] = 0
                else:
                    for l in range (4):
                        x, y = getState([j, k], l)
                        temp[j][k] += (reward_t[j][k] + post_value_t[x][y]) * 0.25
        post_value_t = temp
    return post_value_t

policy_eval(5000)

def policy_improv(iter, grid_size = 7):
    post_value_t = policy_eval(iter)
    policy_t = np.full([grid_size, grid_size, 4], 0.25)
    
    for j in range(grid_size):
        for k in range(grid_size):
            if j == k and j == grid_size - 1:
                policy_t[j][k] = [0, 0, 0, 0]
            else:
                for l in range(4):
                    x, y = getState([j, k], l)
                    policy_t[j][k][l] = post_value_t[x][y]
                policy_max = policy_t[j][k].max()
                count = 0
                for l in range(4):
                    if policy_t[j][k][l] == policy_max:
                        count += 1
                for l in range(4):
                    if policy_t[j][k][l] == policy_max:
                          policy_t[j][k][l] = 1 / count
                    else:
                          policy_t[j][k][l] = 0.0

    return post_value_t, policy_t

value_func, policy = policy_improv(3000)

value_func

for i in range(7):
    for j in range(7):
        print("[U : {}, D : {}, L : {}, R : {}], ".format(policy[i][j][0], policy[i][j][1], policy[i][j][2], policy[i][j][3]), end = '')
    print("\n", end = '')

print("action : ")
for i in range(7):
    for j in range(7):
        print("[", end = '')
        if(policy[i][j][0] == policy[i][j].max() and [i, j] != [6, 6]):
            print("U, ", end = '')
        else:
            print("X, ", end = '')
        if(policy[i][j][1] == policy[i][j].max() and [i, j] != [6, 6]):
            print("D, ", end = '')
        else:
            print("X, ", end = '')
        if(policy[i][j][2] == policy[i][j].max() and [i, j] != [6, 6]):
            print("L, ", end = '')
        else:
            print("X, ", end = '')
        if(policy[i][j][3] == policy[i][j].max() and [i, j] != [6, 6]):
            print("R], ", end = '')
        else:
            print("X], ", end = '')
    print("\n", end = '')

def value_iter(iter, grid_size = 7):
    post_value_t = np.full([grid_size, grid_size], -1.0)
    action_t = np.full([grid_size, grid_size, 4], 1)
    action_t[grid_size - 1][grid_size - 1] = [0, 0, 0, 0]
    reward_t = getRewardTable()

    for i in range(iter):
        temp = np.full([grid_size, grid_size], 0.0)
        for j in range(grid_size):
            for k in range (grid_size):
                if j == k and j == grid_size - 1:
                    temp[j][k] = 0.0
                    action_t[j][k] = [0.0, 0.0, 0.0, 0.0]
                else: 
                    for l in range (4):
                        x, y = getState([j, k], l)
                        action_t[j][k][l] = reward_t[j][k] + post_value_t[x][y]
                    temp[j][k] = action_t[j][k].max()
                    for l in range (4):
                        if(action_t[j][k][l] == temp[j][k]):
                            action_t[j][k][l] = 1
                        else:
                            action_t[j][k][l] = 0
        post_value_t = temp
    return post_value_t, action_t

value_func, action = value_iter(13)

value_func

for i in range(7):
    for j in range(7):
        print("[U : {}, D : {}, L : {}, R : {}], ".format(round(action[i][j][0], 3), round(action[i][j][1], 3), round(action[i][j][2], 3), round(action[i][j][3], 3)), end = '')
    print("\n", end = '')

for i in range(7):
    for j in range(7):
        print("[", end = '')
        if(action[i][j][0] == 1 and [i, j] != [6, 6]):
            print("U, ", end = '')
        else:
            print("X, ", end = '')
        if(action[i][j][1] == 1 and [i, j] != [6, 6]):
            print("D, ", end = '')
        else:
            print("X, ", end = '')
        if(action[i][j][2] == 1 and [i, j] != [6, 6]):
            print("L, ", end = '')
        else:
            print("X, ", end = '')
        if(action[i][j][3] == 1 and [i, j] != [6, 6]):
            print("R], ", end = '')
        else:
            print("X], ", end = '')
    print("\n", end = '')